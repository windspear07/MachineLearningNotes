

# 提升树

1. 提升树boostring tree是以决策树为基本学习器的提升方法。它被认为是统计学习中性能最好的方法之一。
2. 对分类问题，提升树中的决策树是二叉决策树；对回归问题，提升树中的决策树是二叉回归树。
3. $f(\vec x)=f_M(\vec x)=\sum_{m=1}^Mh_m(\vec x; \Theta_m)$
    - $h_m(\vec x; \Theta_m)$表示第m个决策树
    - $\Theta_m$表示第m个决策树的参数
    - $M$为决策树的数量
4. 提升树的向前分布算法：
    - 首先确定初始提升树 $f_0(\vec x)=0$
    - 第m步模型 $f_m(\vec x)=f_{m-1}(\vec x) + h_m(\vec x;\Theta_m)$
    - 通过经验风险极小化确定第m个决策树的参数 $\Theta_m=arg min_{\Theta_m}\sum_{i=1}^NL(\hat y_i,f_m(\vec x))$
5. 损失函数
    - 回归问题 $L(y1,y2)=(y1-y2)^2$
    - 分类 $L(y_1,y_2)=e^{-y_1y_2}$