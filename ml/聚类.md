
# 原型聚类

1. 距离的特征：非负性、统一性、对称性、传递性。
    - 闵可夫斯基距离（有序属性）
$dist_{mk}(x_i,x_j)=(\sum_{u=1}^n |x_{iu}-x_{ju}|^p)^{\frac{1}{p}}$

    - VDM距离Value Difference Metric：考虑非数值类属性（如属性取值为：中国，印度，美国，英国），令$m_{d,a}$表示$x_d=a$的样本数；$m_{d,a,k}$表示$x_d=a$且位于簇$\mathbb{C}_k$中的样本的数量。则在属性d上的两个取值$a,b$之间的VDM距离为：
    
    $$VDM_p(a,b)=(\sum_{k=1}^K |\frac{m_{d,a,k}}{m_{d,a}}-\frac{m_{d,b,k}}{m_{d,b}}|)^{1/p}$$
    
    该距离刻画的是：属性取值在各簇上的频率分布之间的差异


2. k-均值算法
    - input：样本集$D={x_1,x_2,\dots,x_n}$,聚类数 $k$
    - 过程：
        - 从D中随机选择k个样本作为初始均值向量$\{\mu_1,\mu_2,\dots,\mu_k\}$
        - repeat:
            - 初始化阶段：取$\mathbb{C}_k = \empty$
            - 划分阶段：令$i=1,2,\dots,N:$
            计算$\vec x_i$的簇标记 $\lambda_i=arg min _k||\vec x_i - \vec \mu_k||$.即将距离最近的均值向量标识。
            $\mathbb{C}_{\lambda_i}=\mathbb{C}_{\lambda_i} \bigcup \{x_i\}$ 
            - 重新计算中心： $\vec \mu_k=\frac{1}{|\mathbb{C}_k|}\sum_{\vec x_i \in \mathbb{C}}\vec x_i$
            - 终止条件判断
3. 学习向量量化，根据标签属性改进。初始化$k$个变量后，一次扫描，如果与样本相同类则趋近样本，如果不同类则远离样本。

4. 高斯混合模型 mixtrue of gaussian

    n维随机向量的分布公式：
$p(x)=\frac{1}{(2\pi)^{\frac{n}{2}} |\Sigma|^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)}$

    其中$\mu$是n维均值向量，$\Sigma$是协方差矩阵。可将概率密度函数记为
    
    $$p(x|\mu,\Sigma)$$ (2)

    定义高斯混合分布 $P_{M}=\sum_{i=1}^k \alpha_i \cdot p(x|\mu_i,\Sigma_i)$.由k个混合成分组成，每个混合成分对应一个高斯分布。

    $$P_M(z_j=i|x_j)=\frac{P(z_j=i)\cdot P_m(x_j|z_j=i)}{P_m(x_j)} \\
    =\frac{\alpha_i\cdotp(x_j|\mu_i,\Sigma_i)}{\sum_{l=1}^k \alpha_l \cdotp(x_j|\mu_l,\Sigma_l)}$$ (3)

    简要记为 $\gamma_{ji} (i=1,2,\dots,k)$

    从原型聚类的角度来看 高斯混合聚类是采用概率模型(高斯分布)对原型进行刻画，簇划分则由原型对应后验概率确定.