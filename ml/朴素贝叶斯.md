
# 概念

1. 朴素贝叶斯分类器的优点：
    - 性能相当好，它速度快，可以避免维度灾难。
    - 支持大规模数据的并行学习，且天然的支持增量学习。
    - 在数据较少的时候仍有效，可以处理多类别问题
2. 朴素贝叶斯分类器的缺点：
    - 无法给出分类概率，因此难以应用于需要分类概率的场景。
    - 对于数据的准备方式敏感
3. 贝叶斯定理：设试验$E$的样本空间为$\mathbb{E}$，$A$为$E$的事件，$B_1,B_2,\dots,B_n$是样本空间的一个划分，且$p(A)>0, p(B_i) \ge 0(i=1,2,\dots,n)$，则有：

$$p(B_i|A)=\frac{p(A|B_i)p(B_i)}{\sum_{j=1}^n p(A|B_j)p(B_j)}$$
4. 先验概率：根据以往经验和分析得到的概率；后验概率：根据已经发生的时间分析得到的概率。

# bayes

1. 通过训练数据集学习联合概率分布$p(\vec x,y)$,具体的学习下列分布：
- 先验概率分布 $p(y)$
- 条件概率分布 $p(\vec x|y)=p(x_1,x_2,\dots,x_n|y)$
2. 特征独立性假设

$$p(\vec x|y)=p(x_1,x_2,\dots,x_n|y)=\prod_{j=1}^n p(x_j|y)$$

简单了，但是牺牲了一定的分类准确率。
3. 有

$$p(y|\vec x)=\frac{p(\vec x|y)p(y)}{\sum_{y'}p(\vec|y')p(y')}$$

$$p(y|\vec x)=\frac{p(y)\prod_{i=1}^n p(x_i|y)}{\sum_{y'}p(\vec|y')p(y')}$$

$$f(\vec x) = arg max \frac{p(y)\prod_{i=1}^n p(x_i|y)}{\sum_{y'}p(\vec|y')p(y')}$$

去除分母

$$f(\vec x) = arg max p(y)\prod_{i=1}^n p(x_i|y)$$

## 期望风险最小化

1. 贝叶斯分类器是后验概率最大化，等价于期望风险最小化。

2. 损失函数：

$$L(y,f(\vec x) ) = \Bigg\{ \begin{array}{ll} 
 1 & \textrm{y != f(x)} \\
 0 & \textrm{y = f(x)} \\
\end{array}$$

$$R_{exp}(f)=\mathbb{E}[L(y,f(\vec x))]=\sum_{\vec x \in \chi}\sum_{y \in \mathbb{Y}}L(y,f(\vec x))p(\vec x,y)$$

即，使后验概率最大化。

## 算法

1. 学习意味着估计概率$p(y), p(x_i|y)$ .
2. 用极大似然估计相应概率。
    - 先验概率$p(y)$的极大似然估计：$p(y=c_k)=\frac{1}{N}\sum_{i=1}^N I(\hat y = c_k)$
    - 设第j个特征$x_j$可能的取值${a_{j,1},a_{j,2},\dots,a_{j,s_j}}$,则条件概率$p(x_j=a_{j,l}|y=c_k)$的极大似然估计为:

    $$p(x_j=a_{j,l}|y=c_k)=\frac{\sum_{i=1}^N I(x_{i,j}=a_{i,j},\hat y=c_k)}{\sum_{i=1}^N I(\hat y = c_k)}$$
3. 具体算法：
    - input：
        - 训练集$\mathbb{D}=\{(\vec x_1,\hat y_1),(\vec x_2,\hat y_2),\dots,(\vec x_N,\hat y_N)\}$
        $\vec x=(x_{i,1},x_{i,2},\dots,x_{i,n})^T$
        $x_{i,j} \in \{a_{j,1},a_{j,2},\dots,a_{j,s_j}\}$
        - 实例 $\vec x$
    - output: $\vec x$的分类
    - steps
        - 计算$p(y=c_k)$,$p(x_j=a_{j,l} | y = c_k)$
        - 对应给定实例$\vec x$，计算$p(y=c_k)\prod_{j=1}^n p(x_j|y=c_k)$
        - 确定 $\hat y = argmaxk_{c_k} p(y=c_k)\prod_{j=1}^n p(x_j|y=c_k)$

## 贝叶斯估计









$$\sum_{i=0}^{+\infty} \frac{1}{2^i} = 2$$ (1)